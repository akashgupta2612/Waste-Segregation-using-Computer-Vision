# -*- coding: utf-8 -*-
"""training78.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HPHiJJinMxpBpz9T5lb6NhCPiGqFvjsf
"""

import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
import keras.optimizers as kp

from google.colab import drive
drive.mount('/content/gdrive')

#Data Preparaion
train = {'labels' : [], 'features' : []}
classes = ['electronics', 'polybag', 'glass', 'metal', 'plastic', 'paperbag', 'papercup', 'paperwrap', 'newspaper', 'apple', 'banana', 'orange', 'cardboard', 'paper']
items = ['e', 'p', 'glass', 'metal', 'plastic','p', 'p', 'p', 'n', 'apple', 'b', 'o', 'cardboard', 'paper']
numOfImg =[160, 202, 501, 410, 482, 201, 223, 201, 235, 337, 310, 302, 403, 594]
numOfClasses = len(classes)
count = 0
for i in range(0, numOfClasses):
    for j in range(0, numOfImg[i]):
        tempImg = Image.open('gdrive/My Drive/Minor/Data/{0}/{1}{2}.jpg'.format(classes[i], items[i], j+1))
        reImg = tempImg.resize((200, 200))
       
        train['labels'].insert(count, i)
        train['features'].insert(count, np.array(reImg))
        count =count+1
        
x, y = np.array(train['features']), np.array(train['labels'])
print(x.shape)
print(y.shape)

x, y = shuffle(x, y)

#Separating Training, Testing Data and Validation Data

xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2)
print(xTrain.shape)
print(yTrain.shape)

fig, axes = plt.subplots(3, 3) 
for i, ax in enumerate(axes.flat):
  ax.imshow(xTrain[i+45]) 
  ax.set_xlabel('class: {}'.format(classes[yTrain[i+45]])) 
  ax.set_xticks([]) 
  ax.set_yticks([])
plt.tight_layout()

mean = np.mean(xTrain)
std = np.std(xTrain)
xTrainNorm = (xTrain-mean)/std
xTestNorm = (xTest-mean)/std

imageShape = xTrainNorm[0].shape
imageShape

xTrainNorm[4]

#Topology 
cnnModel = Sequential()
cnnModel.add(Conv2D(32, (3, 3), input_shape = imageShape, activation = 'relu'))
cnnModel.add(MaxPooling2D(pool_size = (2,2)))

cnnModel.add(Conv2D(64, (3, 3), activation = 'relu'))
cnnModel.add(MaxPooling2D(pool_size = (2,2)))
cnnModel.add(Dropout(0.25))

cnnModel.add(Conv2D(64, (3, 3), activation = 'relu'))
cnnModel.add(MaxPooling2D(pool_size = (2,2)))
cnnModel.add(Dropout(0.25))

cnnModel.add(Conv2D(128, (3, 3), activation = 'relu'))
cnnModel.add(MaxPooling2D(pool_size = (3,3)))
cnnModel.add(Dropout(0.25))

cnnModel.add(Conv2D(128, (5, 5), activation = 'relu'))
cnnModel.add(MaxPooling2D(pool_size = (2,2)))
cnnModel.add(Dropout(0.25))


cnnModel.add(Flatten())
cnnModel.add(Dense(output_dim = 512, activation = 'relu'))
cnnModel.add(Dropout(0.25))
cnnModel.add(Dense(output_dim = 256, activation = 'relu'))
cnnModel.add(Dropout(0.25))
cnnModel.add(Dense(output_dim = 256, activation = 'relu'))
cnnModel.add(Dropout(0.25))
cnnModel.add(Dense(output_dim = 128, activation = 'relu'))
cnnModel.add(Dropout(0.25))
cnnModel.add(Dense(output_dim = 64, activation = 'relu'))
cnnModel.add(Dropout(0.25))
cnnModel.add(Dense(output_dim = 14, activation = 'softmax'))

opt = kp.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=1e-6)
cnnModel.compile(loss = 'sparse_categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])

history = cnnModel.fit(xTrainNorm, yTrain, batch_size = 64, nb_epoch = 100, verbose = 1, validation_data=(xTestNorm, yTest))

score = cnnModel.evaluate(xTestNorm, yTest, verbose = 0)
print('Test Loss: {:.4f}'.format(score[0]))
print('Test Accuracy: {:.2f}%'.format(score[1]*100))

# %matplotlib inline
accuracy = history.history['acc']
val_accuracy = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(accuracy))
plt.plot(epochs, accuracy, 'bo', label='Training Accuracy')
plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')
plt.title('Training and Validation accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

predictedClasses = cnnModel.predict_classes(xTestNorm)
trueClasses = yTest

confMatrix = confusion_matrix(trueClasses, predictedClasses)
confMatrix

fig, axes = plt.subplots(3, 3)
for i, ax in enumerate(axes.flat):
  ax.imshow(xTest[i+123])
  ax.set_title('Act:{0},Pr:{1}'.format(classes[yTest[i+123]], classes[predictedClasses[i+123]]))
  ax.set_xticks([])
  ax.set_yticks([])
  
plt.tight_layout()

cnnModel.save_weights('gdrive/My Drive/weights78.h5')

cnnModel.summary()

